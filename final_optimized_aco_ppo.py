# final_optimized_aco_ppo.py - æœ€ç»ˆä¼˜åŒ–ç‰ˆACO-PPO
# è§£å†³æ³›åŒ–æ€§é—®é¢˜ï¼Œæå‡æµ‹è¯•ç¨³å®šæ€§

import numpy as np
import torch
import torch.optim as optim
import matplotlib.pyplot as plt
import time
from copy import deepcopy

import config_matrix as config
from stability_fixed_aco_ppo import StabilizedACOPPOAgent, StabilizedACOPPOEnv


class FinalOptimizedAgent(StabilizedACOPPOAgent):
    """æœ€ç»ˆä¼˜åŒ–æ™ºèƒ½ä½“ - æå‡æ³›åŒ–èƒ½åŠ›"""

    def __init__(self, env, device='cpu'):
        super().__init__(env, device)

        # ğŸ”§ æå‡æ³›åŒ–èƒ½åŠ›çš„å‚æ•°è°ƒæ•´
        self.entropy_coef = 0.03  # å¢åŠ æ¢ç´¢
        self.n_updates_per_iteration = 4  # é€‚åº¦å¢åŠ æ›´æ–°
        self.clip_ratio = 0.12  # ç¨å¾®æ”¾æ¾è£å‰ª

        # ğŸ”§ ç»éªŒå›æ”¾ç¼“å†²åŒºï¼ˆæå‡æ ·æœ¬æ•ˆç‡ï¼‰
        self.experience_buffer = []
        self.buffer_capacity = 1000
        self.use_experience_replay = True

        print(f"ğŸ¯ æœ€ç»ˆä¼˜åŒ–æ™ºèƒ½ä½“:")
        print(f"   å¢å¼ºæ¢ç´¢: entropy_coef={self.entropy_coef}")
        print(f"   ç»éªŒå›æ”¾: å®¹é‡={self.buffer_capacity}")


class FinalOptimizedEnv(StabilizedACOPPOEnv):
    """æœ€ç»ˆä¼˜åŒ–ç¯å¢ƒ - å¢å¼ºæ³›åŒ–è®­ç»ƒ"""

    def __init__(self):
        super().__init__()

        # ğŸ”§ æ›´å¼ºçš„æ³›åŒ–è®­ç»ƒè®¾ç½®
        self.training_difficulty_levels = [
            {'max_distance': 6.0, 'min_distance': 3.0},  # ç®€å•
            {'max_distance': 8.0, 'min_distance': 4.0},  # ä¸­ç­‰
            {'max_distance': 10.0, 'min_distance': 5.0}  # å›°éš¾
        ]
        self.current_difficulty = 0
        self.episodes_per_difficulty = 100
        self.episode_count = 0

        print(f"ğŸ¯ æœ€ç»ˆä¼˜åŒ–ç¯å¢ƒ:")
        print(f"   æ¸è¿›éš¾åº¦è®­ç»ƒï¼Œ{len(self.training_difficulty_levels)}ä¸ªéš¾åº¦çº§åˆ«")

    def reset(self, seed=None, options=None, major_reset=False):
        # ğŸ”§ æ¸è¿›éš¾åº¦è°ƒæ•´
        if major_reset:
            self.episode_count += 1
            if self.episode_count % self.episodes_per_difficulty == 0:
                self.current_difficulty = min(
                    self.current_difficulty + 1,
                    len(self.training_difficulty_levels) - 1
                )
                if self.episode_count % (self.episodes_per_difficulty * 2) == 0:
                    print(f"   ğŸ“ˆ éš¾åº¦æå‡åˆ°çº§åˆ« {self.current_difficulty + 1}")

        obs, info = super().reset(seed, options, major_reset)

        # ğŸ”§ æ ¹æ®éš¾åº¦è°ƒæ•´ç›®æ ‡è·ç¦»
        if major_reset:
            difficulty = self.training_difficulty_levels[self.current_difficulty]
            max_attempts = 50

            for _ in range(max_attempts):
                distance = np.random.uniform(-self.env_bounds * 0.8, self.env_bounds * 0.8)
                angle = np.random.uniform(0, 2 * np.pi)

                # æ ¹æ®éš¾åº¦è®¾ç½®è·ç¦»
                target_distance = np.random.uniform(
                    difficulty['min_distance'],
                    difficulty['max_distance']
                )

                candidate_target = self.agent_pos + target_distance * np.array([
                    np.cos(angle), np.sin(angle)
                ])

                if (np.all(np.abs(candidate_target) < self.env_bounds) and
                        not self._is_collision(candidate_target)):
                    self.target_pos = candidate_target
                    break

        return obs, info


def comprehensive_final_test():
    """ç»¼åˆæœ€ç»ˆæµ‹è¯•"""
    print(f"ğŸ¯ ACO-PPOæœ€ç»ˆç»¼åˆæµ‹è¯•")
    print(f"   å½“å‰æ—¶é—´: 2025-08-22 04:37:56")
    print(f"   ç”¨æˆ·: tongjiliuchongwen")
    print(f"=" * 70)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # ğŸ”§ æœ€ç»ˆä¼˜åŒ–è®­ç»ƒ
    env = FinalOptimizedEnv()
    agent = FinalOptimizedAgent(env, device)

    print(f"ğŸ¯ æœ€ç»ˆä¼˜åŒ–è®­ç»ƒ (80æ¬¡è¿­ä»£)...")
    history = agent.train(num_iterations=80, episodes_per_iteration=25)

    # ğŸ”§ å¤šè½®æ¬¡ç¨³å®šæ€§æµ‹è¯•
    print(f"\nğŸ§ª å¤šè½®æ¬¡ç¨³å®šæ€§æµ‹è¯•...")
    all_test_results = []

    test_configs = [
        {"episodes": 20, "name": "æ ‡å‡†æµ‹è¯•"},
        {"episodes": 30, "name": "é•¿æµ‹è¯•"},
        {"episodes": 15, "name": "å¿«é€Ÿæµ‹è¯•"}
    ]

    for config_item in test_configs:
        print(f"\nğŸ“‹ {config_item['name']} ({config_item['episodes']}ä¸ªepisodes):")
        round_results = []

        for round_num in range(5):
            success_rate = test_comprehensive_final(env, agent, config_item['episodes'])
            round_results.append(success_rate)
            all_test_results.append(success_rate)
            print(f"   è½®æ¬¡{round_num + 1}: {success_rate:.1%}")

        round_avg = np.mean(round_results)
        round_std = np.std(round_results)
        print(f"   {config_item['name']}å¹³å‡: {round_avg:.1%} Â± {round_std:.1%}")

    # ğŸ”§ ç»¼åˆåˆ†æ
    overall_avg = np.mean(all_test_results)
    overall_std = np.std(all_test_results)
    consistency_score = 1 - (overall_std / max(overall_avg, 0.01))

    print(f"\nğŸ“Š æœ€ç»ˆç»¼åˆæµ‹è¯•ç»“æœ:")
    print(f"   æ€»ä½“å¹³å‡æˆåŠŸç‡: {overall_avg:.1%} Â± {overall_std:.1%}")
    print(f"   æµ‹è¯•ä¸€è‡´æ€§è¯„åˆ†: {consistency_score:.1%}")
    print(f"   æœ€ä½³è®­ç»ƒæˆåŠŸç‡: {agent.best_success_rate:.1%}")
    print(f"   æœ€ç»ˆè®­ç»ƒæˆåŠŸç‡: {history['success_rates'][-1]:.1%}")

    # ğŸ”§ æ€§èƒ½ç¨³å®šæ€§åˆ¤æ–­
    training_final_10 = np.mean(history['success_rates'][-10:])
    if overall_avg >= training_final_10 * 0.7:
        generalization_quality = "ä¼˜ç§€"
        generalization_icon = "ğŸ‰"
    elif overall_avg >= training_final_10 * 0.5:
        generalization_quality = "è‰¯å¥½"
        generalization_icon = "âœ…"
    else:
        generalization_quality = "éœ€æ”¹è¿›"
        generalization_icon = "âš ï¸"

    print(f"   æ³›åŒ–èƒ½åŠ›è¯„ä¼°: {generalization_icon} {generalization_quality}")
    print(f"   è®­ç»ƒç¨³å®šæ€§: {'âœ… æ— å´©æºƒ' if history['rollbacks'][-1] == 0 else 'âš ï¸ æœ‰å›æ»š'}")

    # ğŸ”§ è¯¦ç»†å¯è§†åŒ–
    create_final_analysis_plots(history, all_test_results, agent)

    return overall_avg, consistency_score


def test_comprehensive_final(env, agent, num_episodes):
    """æœ€ç»ˆæµ‹è¯•å‡½æ•°"""
    successes = 0

    for episode in range(num_episodes):
        obs, _ = env.reset(major_reset=True)
        hidden_state = None
        done = truncated = False
        steps = 0

        while not (done or truncated) and steps < 250:  # å¢åŠ æµ‹è¯•æ­¥æ•°
            action, _, hidden_state = agent.get_action(obs, hidden_state)
            obs, reward, done, truncated, info = env.step(action)
            steps += 1

        if info.get('target_found', False):
            successes += 1

    return successes / num_episodes


def create_final_analysis_plots(history, test_results, agent):
    """åˆ›å»ºæœ€ç»ˆåˆ†æå›¾è¡¨"""
    plt.figure(figsize=(18, 10))

    # è®­ç»ƒæˆåŠŸç‡æ›²çº¿
    plt.subplot(2, 4, 1)
    plt.plot(history['success_rates'], 'b-', linewidth=2, label='Training')
    if agent.best_success_rate > 0:
        plt.axhline(y=agent.best_success_rate, color='r', linestyle='--', alpha=0.7,
                    label=f'Best: {agent.best_success_rate:.1%}')
    plt.title('Training Progress')
    plt.xlabel('Iteration')
    plt.ylabel('Success Rate')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # å­¦ä¹ ç‡å˜åŒ–
    plt.subplot(2, 4, 2)
    plt.plot(history['learning_rates'], 'green', linewidth=2)
    plt.title('Learning Rate Schedule')
    plt.xlabel('Iteration')
    plt.ylabel('Learning Rate')
    plt.yscale('log')
    plt.grid(True, alpha=0.3)

    # å¥–åŠ±è¶‹åŠ¿
    plt.subplot(2, 4, 3)
    plt.plot(history['avg_rewards'], 'purple', linewidth=2)
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    plt.title('Reward Trend')
    plt.xlabel('Iteration')
    plt.ylabel('Average Reward')
    plt.grid(True, alpha=0.3)

    # æµ‹è¯•ç»“æœåˆ†å¸ƒ
    plt.subplot(2, 4, 4)
    plt.hist(test_results, bins=max(5, len(set(test_results)) if len(set(test_results)) > 1 else 5),
             alpha=0.7, edgecolor='black')
    plt.axvline(x=np.mean(test_results), color='r', linestyle='--',
                label=f'Mean: {np.mean(test_results):.1%}')
    plt.title('Test Results Distribution')
    plt.xlabel('Success Rate')
    plt.ylabel('Frequency')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # è®­ç»ƒvsæµ‹è¯•å¯¹æ¯”
    plt.subplot(2, 4, 5)
    final_training = np.mean(history['success_rates'][-10:])
    test_avg = np.mean(test_results)

    categories = ['Training\n(Final)', 'Testing\n(Average)']
    values = [final_training, test_avg]
    colors = ['skyblue', 'lightcoral']

    bars = plt.bar(categories, values, color=colors, alpha=0.8)
    plt.title('Training vs Testing')
    plt.ylabel('Success Rate')

    for bar, value in zip(bars, values):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                 f'{value:.1%}', ha='center', va='bottom', fontweight='bold')

    # ç¨³å®šæ€§åˆ†æ
    plt.subplot(2, 4, 6)
    window_size = 10
    rolling_std = []
    for i in range(window_size, len(history['success_rates'])):
        window_data = history['success_rates'][i - window_size:i]
        rolling_std.append(np.std(window_data))

    plt.plot(range(window_size, len(history['success_rates'])), rolling_std, 'orange', linewidth=2)
    plt.title('Training Stability')
    plt.xlabel('Iteration')
    plt.ylabel('Rolling Std')
    plt.grid(True, alpha=0.3)

    # å­¦ä¹ é˜¶æ®µåˆ†æ
    plt.subplot(2, 4, 7)
    n_phases = 4
    phase_size = len(history['success_rates']) // n_phases
    phase_avgs = []

    for i in range(n_phases):
        start_idx = i * phase_size
        end_idx = (i + 1) * phase_size if i < n_phases - 1 else len(history['success_rates'])
        phase_avg = np.mean(history['success_rates'][start_idx:end_idx])
        phase_avgs.append(phase_avg)

    plt.bar(range(1, n_phases + 1), phase_avgs, alpha=0.7, color='lightgreen')
    plt.title('Learning Phases')
    plt.xlabel('Phase')
    plt.ylabel('Average Success Rate')
    plt.xticks(range(1, n_phases + 1))
    plt.grid(True, alpha=0.3)

    # ç»¼åˆè¯„åˆ†é›·è¾¾å›¾
    plt.subplot(2, 4, 8)

    # è®¡ç®—å„ç»´åº¦è¯„åˆ†
    final_success = min(final_training / 0.5, 1.0)  # åŸºäº50%ç›®æ ‡
    test_success = min(test_avg / 0.3, 1.0)  # åŸºäº30%ç›®æ ‡
    stability = min(1 - np.std(history['success_rates'][-20:]) / max(np.mean(history['success_rates'][-20:]), 0.01),
                    1.0)
    consistency = min(1 - np.std(test_results) / max(np.mean(test_results), 0.01), 1.0)

    scores = [final_success, test_success, stability, consistency]
    labels = ['Training\nSuccess', 'Test\nSuccess', 'Training\nStability', 'Test\nConsistency']

    angles = np.linspace(0, 2 * np.pi, len(scores), endpoint=False).tolist()
    scores += scores[:1]  # é—­åˆå›¾å½¢
    angles += angles[:1]

    ax = plt.subplot(2, 4, 8, projection='polar')
    ax.plot(angles, scores, 'o-', linewidth=2, color='blue')
    ax.fill(angles, scores, alpha=0.25, color='blue')
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(labels)
    ax.set_ylim(0, 1)
    ax.set_title('Performance Radar', pad=20)

    plt.tight_layout()
    plt.savefig('final_comprehensive_analysis.png', dpi=150, bbox_inches='tight')
    plt.close()

    print(f"ğŸ“Š ä¿å­˜æœ€ç»ˆç»¼åˆåˆ†æå›¾: final_comprehensive_analysis.png")


if __name__ == "__main__":
    start_time = time.time()

    overall_success, consistency = comprehensive_final_test()

    total_time = time.time() - start_time

    print(f"\nğŸ æœ€ç»ˆç»¼åˆæµ‹è¯•æ€»ç»“:")
    print(f"   æ€»ç”¨æ—¶: {total_time / 60:.1f} åˆ†é’Ÿ")
    print(f"   ç»¼åˆæˆåŠŸç‡: {overall_success:.1%}")
    print(f"   æµ‹è¯•ä¸€è‡´æ€§: {consistency:.1%}")

    # æœ€ç»ˆè¯„ä»·
    if overall_success >= 0.25 and consistency >= 0.7:
        final_grade = "A+ ä¼˜ç§€"
        final_icon = "ğŸ‰"
    elif overall_success >= 0.2 and consistency >= 0.6:
        final_grade = "A è‰¯å¥½"
        final_icon = "ğŸ¯"
    elif overall_success >= 0.15 and consistency >= 0.5:
        final_grade = "B+ å¯æ¥å—"
        final_icon = "âœ…"
    elif overall_success >= 0.1:
        final_grade = "B éœ€æ”¹è¿›"
        final_icon = "âš ï¸"
    else:
        final_grade = "C ä¸ç†æƒ³"
        final_icon = "âŒ"

    print(f"\n{final_icon} æœ€ç»ˆè¯„ä»·: {final_grade}")
    print(f"   ACO-PPOç³»ç»Ÿ {'æˆåŠŸå®ç°ç›®æ ‡' if overall_success >= 0.2 else 'ä»éœ€ä¼˜åŒ–'}")